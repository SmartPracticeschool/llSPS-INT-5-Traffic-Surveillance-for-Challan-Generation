{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D   #adding convolution layer : Cl for feature mapping \n",
    "from keras.layers import MaxPooling2D  # to extract the exact pooling\n",
    "from keras.layers import Flatten # multi to single dimential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0203 15:04:08.433871 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preprocessing is done in the convolution layer min preprocessing required\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "W0203 15:04:09.036194 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0203 15:04:09.046228 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32,3,3, input_shape = (64,64,3), activation = 'relu')) #params 1. no.of feature detectors 2 n 3. size of the feature detector matrix i.e., here 3*3 4. i/p layer i.e., no.of pixcels containing rows, cloumns, channels for grayscale imgs i.e, bnw imgs then channel =1 else channel = 3 5. at times the result might b negative pixcels to avoid the negative pixcels in CNN we use activitation function using the activation function non linearity can also b removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0203 15:04:09.498298 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(MaxPooling2D(pool_size = (2,2))) #mention the pool size i.e, from the big img a small matrix here a 2*2 matrix is taken n the max feature is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) #image features r there n then this is given as the i/p to the ANN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128, kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=128,activation = 'relu', init='random_uniform'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"random_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim=1 ,activation = 'sigmoid', init='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0203 15:04:11.523269 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0203 15:04:11.612231 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0203 15:04:11.626787 13808 deprecation.py:323] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam' , loss= 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator  #preprocess the images based on the mentioned parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2 , zoom_range = 0.2, horizontal_flip = True) #to the images we apply few geometrical transformations to avoid over fitting\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174 images belonging to 3 classes.\n",
      "Found 96 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'C:\\smartbridge\\datasets\\Traffic dataset\\trainingset', target_size = (64,64),  batch_size = 32, class_mode = 'binary')\n",
    "x_test = train_datagen.flow_from_directory(r'C:\\smartbridge\\datasets\\Traffic dataset\\testset', target_size = (64,64),  batch_size = 32, class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lane crossing': 0, 'normal': 1, 'wrong parking': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)  # to represent wat represents wat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=1, validation_data=<keras_pre..., steps_per_epoch=250, validation_steps=2000)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "W0203 15:04:20.417197 13808 deprecation_wrapper.py:119] From C:\\Users\\Prathyusha Vedula\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "250/250 [==============================] - 597s 2s/step - loss: -1.4272 - acc: 0.8492 - val_loss: -3.4868 - val_acc: 0.7813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x158d1c9eda0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train, samples_per_epoch = 8000, epochs = 1, validation_data = x_test, nb_val_samples = 2000) #testing n training is done at the same time hence results produces 2 accuracies 1. acc i.e, training accuracy 2. val_acc i.e., validation or testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trafiic.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"trafiic.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss= 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    try:\n",
    "        frame=cv2.imread(frame)\n",
    "        img=resize(frame,(64,64))\n",
    "        img=np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img=img/255.0\n",
    "        prediction=model.predict(img)\n",
    "        pred_class=model.predict_classes(img)\n",
    "        #print(prediction)\n",
    "        #print(pred_class)\n",
    "        return pred_class\n",
    "    except AttributeError:\n",
    "        print(\"Attribute error\")\n",
    "    except UnboundLocalError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "detect(r'C:\\smartbridge\\datasets\\Traffic dataset\\trainingset\\wrong parking\\video6.mp4_frame26.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=smtplib.SMTP('smtp.gmail.com',587)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.starttls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.login('lalithaone.lolla@gmail.com','mig18 rafale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "pred = detect(r'C:\\smartbridge\\datasets\\Traffic dataset\\trainingset\\normal\\normal.mp4_frame1.jpg')\n",
    "if(pred[0][0]==0):\n",
    "    offense = 'Lane Crossing'\n",
    "elif(pred[0][0]==1):\n",
    "    offense = 'normal'\n",
    "else:\n",
    "    offense = 'Wrong Parking'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Challan generated for \"+offense\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Hello my first python gmail integration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sendmail('lalithaone.lolla@gmail.com','pratyusha.vedula@gmail.com',msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code to illustrate Sending mail with attachments \n",
    "# from your Gmail account \n",
    "\n",
    "# libraries to be imported \n",
    "import smtplib \n",
    "from email.mime.multipart import MIMEMultipart \n",
    "from email.mime.text import MIMEText \n",
    "from email.mime.base import MIMEBase \n",
    "from email import encoders \n",
    "\n",
    "fromaddr = \"lalithaone.lolla@gmail.com\"\n",
    "toaddr = \"pratyusha.vedula@gmail.com\"\n",
    "\n",
    "# instance of MIMEMultipart \n",
    "msg = MIMEMultipart() \n",
    "\n",
    "# storing the senders email address \n",
    "msg['From'] = fromaddr \n",
    "\n",
    "# storing the receivers email address \n",
    "msg['To'] = toaddr \n",
    "\n",
    "# storing the subject \n",
    "msg['Subject'] = \"Traffic violation\"\n",
    "\n",
    "# string to store the body of the mail \n",
    "body = \"Please find the attachment for the code and datasets followed by challans of traffic violation system.\"\n",
    "\n",
    "# attach the body with the msg instance \n",
    "msg.attach(MIMEText(body, 'plain')) \n",
    "\n",
    "# open the file to be sent \n",
    "filename = \"challan(wp).png\"\n",
    "attachment = open(r\"C:\\smartbridge\\datasets\\challan(wp).png\", \"rb\") \n",
    "\n",
    "# instance of MIMEBase and named as p \n",
    "p = MIMEBase('application', 'octet-stream') \n",
    "\n",
    "# To change the payload into encoded form \n",
    "p.set_payload((attachment).read()) \n",
    "\n",
    "# encode into base64 \n",
    "encoders.encode_base64(p) \n",
    "\n",
    "p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename) \n",
    "\n",
    "# attach the instance 'p' to instance 'msg' \n",
    "msg.attach(p) \n",
    "\n",
    "# creates SMTP session \n",
    "s = smtplib.SMTP('smtp.gmail.com', 587) \n",
    "\n",
    "# start TLS for security \n",
    "s.starttls() \n",
    "\n",
    "# Authentication \n",
    "s.login(fromaddr, \"mig18 rafale\") \n",
    "\n",
    "# Converts the Multipart msg into a string \n",
    "text = msg.as_string() \n",
    "\n",
    "# sending the mail \n",
    "s.sendmail(fromaddr, toaddr, text) \n",
    "\n",
    "# terminating the session \n",
    "s.quit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
